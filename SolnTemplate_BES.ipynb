{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>CMPE 462 - Project 1<br>Binary Classification with Logistic Regression<br>Due: April 23, 2020, 23:59</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Student ID1:**\n",
    "* **Student ID2:**\n",
    "* **Student ID3:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "In this project, you are going to implement logistic regression from scratch. You are provided\n",
    "a subset of the famous handwritten digit dataset called MNIST. In the subset, you will find images of digit 1 and 5. Therefore, you will be solving a binary classification problem. The project includes feature extraction, model training, and evaluation steps.\n",
    "\n",
    "First, you will load and visualize the data portion we have provided to you and then extract two different set of features to build a classifier on. When you extracted the desired features, you will run your logistic regression implementation with gradient descent on the representations to classify digits into 1 and 5. You will experiment with different learning rates  and regularization parameter ($\\lambda$) and find the optimal $\\lambda$ with 5-fold cross validation. Finally, you will evaluate the implemented models, decide which is the best performing one and visualize a decision boundary.\n",
    "\n",
    "Follow the steps on this notebook that would guide you through the solution step-by-step. Make sure that the notebook reports your work properly and add comments and opinions when necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORTANT NOTE:** You are allowed to use third-party libraries such as `numpy` and `matplotlib` to help you implement necessary procedures. However, you should not import any function that accomplishes the task itself. For instance, you can use `numpy` arrays for matrix operations, but you cannot use `scikit-learn` to implement cross validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Feature Extraction (35 Pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the training/test data and labels as numpy arrays (Hint:`np.load`). Train and test data are 1561x256 and 424x256 dimensional matrices, respectively. Each row in the\n",
    "aforementioned matrices corresponds to an image of a digit. The 256 pixels correspond to a 16x16 image. Label 1 is assigned to digit 1 and label -1 is assigned to digit 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/bin/python\n"
     ]
    }
   ],
   "source": [
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(5 points)** Display two of the digit images, one for digit 1 and one for digit 5. You can use `imshow` function of `matplotlib` library with a suitable colormap. You will first need to reshape 256 pixels to a 16x16 matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=np.load(\"./data/train_data.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels=np.load(\"./data/train_labels.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data=np.load(\"./data/test_data.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels=np.load(\"./data/test_labels.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_one=np.reshape(train_data[0], (16,16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_five= np.reshape(train_data[1560], (16,16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x11ecb7a10>"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(image_one, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x11f11e910>"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(image_five, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(10 points) Implementing Representation 1:** Extract the **symmetry** and **average intensity** features discussed in the class (see logistic regression lecture notes). To compute the intensity features, compute the average pixel value of the image, and for the symmetry feature, compute the negative of the norm of the difference between the image and its y-axis symmetrical. Search numpy's documentation to find the suitable function at each step. You should extract these two features for each image in the training and test sets. As a result, you should obtain a training data matrix of size 1561x2 and test data matrix of size 424x2.\n",
    "\n",
    "Throughout the notebook, we will refer the representation with these two features as **Representation 1** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_of_dif_y_sym( matrix ):\n",
    "   return np.linalg.norm(np.reshape(matrix, (16,16))-np.fliplr(np.reshape(matrix, (16,16))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "symmetry_diff_train_data=np.apply_along_axis(norm_of_dif_y_sym, 1, train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "symmetry_diff_test_data=np.apply_along_axis(norm_of_dif_y_sym, 1, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4.26869254  6.3343369   2.5674501  ... 15.89804705 14.42664382\n",
      " 14.1567059 ]\n"
     ]
    }
   ],
   "source": [
    "print(symmetry_diff_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10.53319192  3.12400128  4.8388106   6.99429296  1.6461373   1.56605045\n",
      "  6.34587252 10.64480812  9.40810289  3.50192604  8.09755296  3.31450811\n",
      "  2.39030919  3.93580665  4.17797224  3.03884781 11.2576844   5.55249061\n",
      "  4.27371712  6.82825893  9.32858832  5.17836306  2.40157823  3.29650573\n",
      "  6.53184568  3.91638992  5.13619217  3.47400403  4.47124435  3.99110486\n",
      "  7.66836084  4.62573583  3.69690682  2.70106572  3.45059647  3.41708882\n",
      " 10.67160288  2.76522296  2.68822767  3.84942333  1.75920891  5.663432\n",
      "  5.47563987  5.76305353  5.5215688   6.49722218  6.54910513  4.16126375\n",
      "  6.03393155  5.67402362  9.96687935  1.97594889  4.71632823  3.08617077\n",
      "  4.52015509  6.15025414  3.19039747  2.01452277  8.81805194  7.9936401\n",
      " 11.27288951  3.84565703  2.62017595 10.28581178  2.46940357  2.9691807\n",
      "  3.20727797  1.89005238  2.84263786  4.27060628  4.33971819  4.45143797\n",
      "  6.80080025  8.21196432  3.58469078  3.48211545  5.76284791  2.72548124\n",
      "  7.91438677  5.65234995  4.27988995  7.26338365  6.38418327  2.80480088\n",
      "  4.9079295   3.85751941  3.56602888  2.67502112  5.75049511  7.83895746\n",
      "  9.05962836  5.84848972  4.50382326  6.00440455  2.64624791  3.37161386\n",
      " 13.36019206  1.86805193  3.05491669  7.11748678  5.23329227  1.81634523\n",
      "  7.75219814  7.87916518 12.03837024  3.96596016  2.6997911   6.66990435\n",
      "  3.62872677  4.22024123 10.03693798  4.15611622  6.5703006   4.95676709\n",
      "  4.94012753  5.39484476  1.21246443  9.24627125  2.64132391  9.93608937\n",
      "  6.26443549 11.28714534  7.66260687  6.62915349  4.35547839  3.61806081\n",
      "  5.89199881  6.10404653  1.76731039 10.86955114  3.80012868  6.44882485\n",
      "  3.3196792   6.27797547 10.28357905  4.8255924   3.66958853  2.34730058\n",
      "  2.93952717  2.24919719  4.07960856  5.13572527  4.80007812  3.42407097\n",
      "  2.78810258  3.03065603  4.79862835  4.16271522  3.27056081  2.17786501\n",
      "  4.57946329  3.22280902 12.38075038  4.22068336  7.72758889 13.35690526\n",
      "  5.74940553  2.73371103 10.33276643  2.9440377   4.12698122  6.03837379\n",
      "  4.10928704  6.27327713  4.5104053   4.24240946  8.98346526  4.88662174\n",
      "  5.4868501   3.10959772  1.49259238  2.93339087  9.82753642  6.37527866\n",
      "  2.89656279  3.95779231  4.97503648  6.19178714  2.61336373  9.6493749\n",
      "  2.3386727   2.4564226   3.18161563  1.97565635  3.69104023  4.46511635\n",
      "  4.9323169   1.99975749  2.90398037  1.75144455  4.60915806  1.80574583\n",
      "  1.79886075  3.67804731  4.58014388  3.26866701  5.07878647  3.12676414\n",
      " 12.32944589  4.29856651  2.23379408  3.44280467  4.60559008  3.7934396\n",
      "  3.75600346  1.16329446  5.08163871  5.48937865  5.17848202  4.29715301\n",
      "  1.58099146  4.82700611  2.43966801 11.2662685   5.47158131  3.85404644\n",
      "  4.11486306  3.99029197  2.61904945  2.84982245  4.80429641  2.65650899\n",
      "  2.66164498  5.13044891  4.45900639  5.09435315  7.75929404  3.4967096\n",
      "  3.23426128  3.47666421  3.00215523 15.96903692 17.06521374 18.003187\n",
      "  4.70985945  3.06070384  2.63670931  3.82760656  4.17806295  7.52074544\n",
      "  3.63379939  4.34475063  2.88937883  3.19138653  2.72789956  4.66195538\n",
      " 12.66809141  5.52620521  6.64231451  2.58511315  2.87333395  3.5339451\n",
      "  2.93007372  3.3983187   1.17200256  6.66450343  2.60392857  7.67459706\n",
      "  3.61647259  2.55666384 12.26654466  5.93743025  7.310593    6.24745612\n",
      " 17.5242367  11.2113307  17.20655916 10.3688741  10.74181167 12.63542251\n",
      " 13.04182296 10.56012282 12.02642366 13.99501297 14.26378393 14.53597021\n",
      " 13.69204988 13.92605874 14.62989323 14.00920619 10.52375532 16.04767441\n",
      " 12.62509263  9.19743649 13.53754675 12.59143495 12.29821946 16.28139159\n",
      " 16.16304767 11.06814483 12.68448028 12.70372654 16.91369498 16.77441677\n",
      " 15.40686711 11.15109941 16.96983329 12.4119183  16.46477282 14.75125174\n",
      " 13.44324314 15.26032641 16.11266843 14.67033517 11.5948931  11.18643715\n",
      " 12.36071414 12.46551098 17.68244129 13.68833679  9.99201601 14.30097703\n",
      " 12.7061774  16.6618691  17.99752316 15.76582145 10.68939474 14.12240751\n",
      " 16.69743771 12.44182495 12.1043308  13.655306   15.02947917 12.25538673\n",
      " 17.03251755 13.88973326 17.76108257 15.35376879 10.58662467 10.29471554\n",
      " 12.96944471 14.75865102 13.39135564 12.35968276 14.06152047 18.09601923\n",
      " 15.13897678 14.72350991 15.23755683 15.66063939 13.00209568 11.71666651\n",
      " 17.84908373 14.72305417 14.67743125 11.99163058 16.52683999 14.45213216\n",
      " 17.17867055 12.22357165 15.17609126 10.22399961 17.1315635  18.16902502\n",
      " 11.57806953 17.55312684 15.49677134 16.26154919 16.64023636 16.77391153\n",
      " 15.44560792 17.75237781 15.83579629 14.84632998 15.04442914 12.41530507\n",
      " 15.87165473 15.69879428 15.09887254 17.24532882 15.7652653  15.26303292\n",
      " 12.98752186 17.15574942 14.25598793 13.13727202 12.62715217 15.51807546\n",
      " 13.93043933 13.35239349 13.07571161 12.10763544 13.285086   15.6135308\n",
      " 16.11722768 15.25116861 13.11828213 15.84025265 15.77767632 13.50877544\n",
      " 16.15737788 14.85323204 11.18781417 13.07167747 12.77035082 18.89358124\n",
      " 18.70536918 12.45543777 15.23555099 13.71893451 13.83832562 16.23852019\n",
      " 13.28787681 12.54134307 12.20935608 18.42965143 15.77249644 12.01259689\n",
      " 14.52236455 14.15666952 10.78513384 12.93464116 14.34382369 17.11601303\n",
      "  9.85481902 13.22009728 12.34794857 13.86489618 14.56530343 15.00307642\n",
      " 16.41929109 16.36197048 14.98672466 13.94558396]\n"
     ]
    }
   ],
   "source": [
    "print(symmetry_diff_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "intensity_train_data=np.mean(train_data, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "intensity_test_data=np.mean(test_data, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.75391406 -0.77228125 -0.76925781 ... -0.26407812 -0.28941406\n",
      " -0.53423828]\n"
     ]
    }
   ],
   "source": [
    "print(intensity_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.68013281 -0.75078125 -0.56176562 -0.51044141 -0.788875   -0.69753516\n",
      " -0.59622266 -0.646625   -0.61341406 -0.59414453 -0.73628125 -0.66494531\n",
      " -0.77066797 -0.74038672 -0.72013281 -0.77421094 -0.77693359 -0.68936719\n",
      " -0.58141016 -0.59074219 -0.56409375 -0.75060938 -0.61794141 -0.60433203\n",
      " -0.57449219 -0.72608984 -0.63162109 -0.71365625 -0.73399609 -0.76015234\n",
      " -0.77635547 -0.77051563 -0.73899219 -0.7730625  -0.52739844 -0.67235156\n",
      " -0.72425781 -0.77819141 -0.66361719 -0.6094375  -0.74559375 -0.74504297\n",
      " -0.64710156 -0.69063672 -0.66680859 -0.64228906 -0.65045703 -0.69364063\n",
      " -0.61085547 -0.63594531 -0.71790625 -0.72008984 -0.74489844 -0.69705078\n",
      " -0.71834766 -0.51111328 -0.54296094 -0.71812109 -0.65021875 -0.48150391\n",
      " -0.56027734 -0.63512109 -0.80535547 -0.79852344 -0.69884766 -0.80431641\n",
      " -0.8150625  -0.77301172 -0.76580859 -0.82319141 -0.82080859 -0.76621094\n",
      " -0.58955469 -0.67101953 -0.71195312 -0.69321094 -0.67123438 -0.76852344\n",
      " -0.74001172 -0.70182031 -0.83106641 -0.71931641 -0.61869531 -0.56447656\n",
      " -0.71174219 -0.75027344 -0.79455859 -0.60290234 -0.59903516 -0.65053516\n",
      " -0.49656641 -0.63594531 -0.658      -0.55019141 -0.6370625  -0.65125781\n",
      " -0.69596094 -0.75315234 -0.67108594 -0.74083984 -0.57032031 -0.67041016\n",
      " -0.64324219 -0.69722656 -0.59933984 -0.65121875 -0.79267969 -0.71089844\n",
      " -0.60766016 -0.62627344 -0.66826562 -0.68480859 -0.76617578 -0.59173438\n",
      " -0.79584375 -0.72864453 -0.75650391 -0.53210156 -0.71596875 -0.70511719\n",
      " -0.64069531 -0.65421484 -0.86798438 -0.86342188 -0.71242187 -0.70947656\n",
      " -0.59143359 -0.61876562 -0.69555078 -0.74823828 -0.54130078 -0.77399609\n",
      " -0.72067578 -0.78203906 -0.55758984 -0.75346484 -0.79365625 -0.63274219\n",
      " -0.52542187 -0.69930469 -0.66012891 -0.74460547 -0.65630078 -0.74319922\n",
      " -0.73889844 -0.69976562 -0.83798047 -0.68199609 -0.74524219 -0.75575\n",
      " -0.76773438 -0.81384766 -0.72973437 -0.79090625 -0.41051953 -0.47379297\n",
      " -0.67521094 -0.77592187 -0.72864453 -0.76254297 -0.80017578 -0.68939453\n",
      " -0.61552344 -0.60591016 -0.68617969 -0.71755078 -0.65921875 -0.78773437\n",
      " -0.66446094 -0.62602734 -0.74454687 -0.68066797 -0.78       -0.82030859\n",
      " -0.79615625 -0.80760937 -0.724875   -0.63422656 -0.74114453 -0.77778125\n",
      " -0.69016016 -0.77726562 -0.81652734 -0.79672266 -0.73300391 -0.64267969\n",
      " -0.69741797 -0.69320703 -0.76202734 -0.78669141 -0.79473828 -0.77655078\n",
      " -0.75771875 -0.73285156 -0.56615234 -0.68053906 -0.83261719 -0.68459766\n",
      " -0.47109375 -0.77903516 -0.76310156 -0.72095313 -0.65265625 -0.64742188\n",
      " -0.74395703 -0.65234766 -0.64544531 -0.69251953 -0.61309375 -0.81478125\n",
      " -0.71810547 -0.49377344 -0.69549219 -0.62477734 -0.79470703 -0.75501172\n",
      " -0.78145703 -0.79937109 -0.76254687 -0.75194531 -0.70097656 -0.71375781\n",
      " -0.65626953 -0.73283984 -0.74362891 -0.63991016 -0.47223437 -0.68930859\n",
      " -0.70411328 -0.83055078 -0.68526562 -0.56377344 -0.48614844 -0.45849609\n",
      " -0.74610156 -0.77209375 -0.72771875 -0.75800781 -0.72065234 -0.6301875\n",
      " -0.59628516 -0.54777734 -0.60390234 -0.64783594 -0.54196094 -0.53553125\n",
      " -0.56575781 -0.64963281 -0.67442578 -0.56740234 -0.57882813 -0.66400781\n",
      " -0.77083594 -0.69133984 -0.76014453 -0.63766797 -0.6675625  -0.73596094\n",
      " -0.80748047 -0.72017578 -0.77021484 -0.61441797 -0.64599609 -0.62204687\n",
      " -0.35032031 -0.49764063 -0.25580078 -0.54045703 -0.41974609 -0.38682422\n",
      " -0.39361328 -0.71815234 -0.29539453 -0.50392969 -0.28723437 -0.52033984\n",
      " -0.21633984 -0.27827344 -0.30807812 -0.50479297 -0.58829297 -0.26557422\n",
      " -0.49666406 -0.60889453 -0.59607031 -0.60207422 -0.53095703 -0.12332031\n",
      " -0.35683984 -0.62055078 -0.40532812 -0.47216406 -0.42978516 -0.42662109\n",
      " -0.09669922 -0.48082422 -0.09705859  0.00690625 -0.11723438 -0.22004688\n",
      " -0.55445703 -0.30524609 -0.22467187 -0.28387109 -0.61751172 -0.61054688\n",
      " -0.61387109 -0.65267188 -0.22116016 -0.44539062 -0.51921094 -0.39514063\n",
      " -0.61671875 -0.46109766 -0.20182812 -0.26128516 -0.364875   -0.44332422\n",
      " -0.40910547 -0.67292969 -0.69245313 -0.43358203 -0.45079687 -0.64640625\n",
      " -0.19190234 -0.34136328 -0.24696484 -0.35254687 -0.62388672 -0.67519531\n",
      " -0.43107031 -0.50446875 -0.36104297 -0.58630859 -0.61500391 -0.32400781\n",
      " -0.40151953 -0.463875   -0.34735547 -0.29760547 -0.19253906 -0.51101953\n",
      " -0.22997266 -0.2874375  -0.4266875  -0.56775    -0.36532031 -0.30920313\n",
      " -0.35434766 -0.59610156 -0.44201953 -0.52978125 -0.15902344  0.21327734\n",
      " -0.50194922 -0.25203516 -0.09818359 -0.34608203 -0.34129297 -0.43075781\n",
      " -0.40682031 -0.21848828 -0.30482813 -0.08958203 -0.52189844 -0.6666875\n",
      " -0.14249219  0.09525391 -0.27482812 -0.19649609 -0.38755859 -0.13260547\n",
      " -0.51717188 -0.07255859 -0.56760937 -0.61555469 -0.54710938 -0.54275391\n",
      " -0.69213281 -0.36916406 -0.46532422 -0.33336719 -0.32282422 -0.36175\n",
      " -0.30197656 -0.54423438 -0.49307422 -0.58626563 -0.31484766 -0.52097266\n",
      " -0.44677344 -0.40996484 -0.42916797 -0.45419531 -0.51291406 -0.29735156\n",
      " -0.17796875 -0.42258203 -0.41195703 -0.16957031 -0.61482031 -0.21801953\n",
      " -0.61267578 -0.49355078 -0.29296875 -0.10014063 -0.25335937 -0.31069531\n",
      " -0.47794531 -0.43009375 -0.69114844 -0.61704297 -0.15745703 -0.22003516\n",
      " -0.63155078 -0.54958594 -0.54166797 -0.55314453 -0.27421094 -0.35169141\n",
      " -0.27935938 -0.10815234 -0.23003906 -0.32082813]\n"
     ]
    }
   ],
   "source": [
    "print(intensity_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "Represent1_train_data = np.column_stack((intensity_train_data,symmetry_diff_train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "Represent1_test_data = np.column_stack((intensity_test_data,symmetry_diff_test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(5 points)** Provide two scatter plots, one for training and one for test data. The plots should contain the average intensity values in the x-axis and symmetry values in the\n",
    "y-axis. Denote the data points of label 1 with blue marker shaped <font color='blue'>o</font> and the data points of label -1 with a red marker shaped <font color='red'>x</font>. (Hint: check out `plt.scatter` and its `marker` and `color` parameters). Explicitly state the axis labels and figure title for both plots (Hint: `plt.xlabel`, `plt.ylabel`, `plt.title`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Represent1_train_data_labelled = np.column_stack((Represent1_train_data,train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Represent1_test_data_labelled = np.column_stack((Represent1_test_data,test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(Represent1_train_data_labelled[:,0], Represent1_train_data_labelled[:,1], c=Represent1_train_data_labelled[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(Represent1_test_data_labelled[:,0], Represent1_test_data_labelled[:,1], c=Represent1_test_data_labelled[:,2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(15 points) Implementing Representation 2:** Come up with an alternative feature extraction approach. The features can again be 2-D, or higher dimensional. If you use any external resource, please cite the references. Explain the feature extraction procedure clearly in your report; if it is an algorithm, provide the algorithm; if it is a function, provide the mathematical expressions. \n",
    "\n",
    "If your proposed features are 2-D or 3-D, provide the scatter plots similar to the previous step.\n",
    "\n",
    "We will refer this representation proposed by you as **Representation 2**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Logistic Regression (40 Pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(20 points)** Implement the logistic regression classifier from scratch with gradient descent and train it using Representation 1 and Representation 2 as inputs. Concatenate\n",
    "1 to your features for the intercept term, such that one data point will look like for 2-D features [1,$x_1$,$x_2$], and the model vector will be [$w_0, w_1, w_2$], where $w_0$ is the intercept parameter. \n",
    "You can refer to lecture notes (Logistic regression slides 29-30) to review the gradient descent learning algorithm and the logistic loss. To implement the gradient of the logistic loss with respect to $w$, first derive its expression by hand. Please include your derivation in your report.\n",
    "\n",
    "To prove that your implementation is converging, keep the loss values at each gradient descent iteration in a numpy array. After the training is finalized, plot the loss values\n",
    "with respect to iteration count (Hint: `plt.plot`). You should observe a decreasing loss as the number of iterations increases. Also, experiment with 5 different learning rates between 0 and 1, and plot the convergence curves for each learning rate in the same plot to observe the effect of the learning rate (step size) on the convergence. \n",
    "\n",
    "To decide when to terminate the gradient descent iterations, check the absolute difference between the current loss value and the loss value of the previous step. If the difference is less than a small number, such as $10^{-5}$, you can exit the loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(10 points)** Implement logistic regression with $\\ell_2$ norm regularization, $||\\mathbf{w}||_{2}^{2}$ . Show that your implementation is working by visualizing the loss over the iterations again. Visualization for a single learning rate and $\\lambda$ suffices. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(10 points)** Implement a 5-fold cross validation procedure to find the optimal $\\lambda$ value for both Representation 1 and 2. Experiment with at least three different $\\lambda$ values between 0 and 1. Report the mean/std of cross validation accuracy of every representation/parameter combination as a table and clearly mark the best configuration in your report. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Evaluation (25 Pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(5 points)** Train the logistic regression classifier on Representation 1 and 2 with the best learning rate you decide. Similarly, train the regularized logistic regression classifier with the best $\\lambda$ you obtained by 5-fold cross validation. Report the training and test classification accuracy as \n",
    "\\begin{align*}\n",
    "\\frac{\\text{number of correctly classified samples}}{\\text{total number of samples}}x100\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(15 points)** Visualize the decision boundary (the line that is given by $\\mathbf{w}^{T}x=0$) obtained from the logistic regression classifier learned without regularization. For this purpose, use only Representation 1. Provide two scatter plots for training and test data points with the decision boundary shown on each of the plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(5 points)** Comment on your work in your report. Include the answers for the following questions in your discussion. \n",
    "\n",
    "* Did regularization improve the generalization performance (did it help reducing the gap between training and test accuracies/errors)? Did you observe any difference between using Representation 1 and 2?\n",
    "* Which feature set did give the best results? Which one is more discriminative?\n",
    "* What would be your next step to improve test accuracy? "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
